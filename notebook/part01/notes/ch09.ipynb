{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# 第9章 EM算法及其推广"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## 习题9.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "&emsp;&emsp;如例9.1的三硬币模型，假设观测数据不变，试选择不同的初值，例如，$\\pi^{(0)}=0.46,p^{(0)}=0.55,q^{(0)}=0.67$，求模型参数为$\\theta=(\\pi,p,q)$的极大似然估计。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答思路：**\n",
    "1. 列出例9.1的三硬币模型；\n",
    "2. 写出三硬币模型的EM算法；\n",
    "3. 根据上述EM算法，编写代码，并求出模型参数的极大似然估计。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答步骤：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第1步：例9.1的三硬币模型**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;根据书中第9章的例9.1（三硬币模型）：\n",
    "\n",
    "> &emsp;&emsp;**例9.1（三硬币模型）** 假设有3枚硬币，分别记作A，B，C。这些硬币正面出现的概率分别是$\\pi$，$p$和$q$。进行如下掷硬币试验：先掷硬币A，根据其结果选出硬币B或硬币C，正面选硬币B，反面选硬币C；然后掷选出的硬币，掷硬币的结果，出现正面记作1，出现方面记作0；独立地重复$n$次试验（这里，$n=10$），观测结果如下：\n",
    "> $$ 1,1,0,1,0,0,1,0,1,1 $$\n",
    "> 假设只能观测到掷硬币的结果，不能观测掷硬币的过程。  \n",
    "> \n",
    "> &emsp;&emsp;三硬币模型可以写作\n",
    "> $$ \\begin{aligned}\n",
    "P(y|\\theta) &= \\sum_z P(y, z | \\theta) = \\sum_z P(z|\\theta) P(y | z, \\theta) \\\\\n",
    "&= \\pi p^y (1-p)^{1-y} + (1 - \\pi) q^y (1- q)^{1-y}\n",
    "\\end{aligned} $$\n",
    "> 这里：\n",
    "> 1. 随机变量$y$是观测变量，表示一次试验观测的结果是1或0；\n",
    "> 2. 随机变量$z$是隐变量，表示未观测到的掷硬币A的结果；\n",
    "> 3. $\\theta=(\\pi, p, q)$是模型参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第2步：三硬币模型的EM算法**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;根据书中第9章的例9.1的三硬币模型的EM算法：\n",
    "\n",
    "> &emsp;&emsp;EM算法首先选取参数的初值，记作$\\theta^{(0)}=(\\pi^{(0)}, p^{(0)}, q^{(0)})$，然后通过下面的步骤迭代计算参数的估计值，直至收敛为止。第$i$次迭代参数的估计值为$\\theta^{(i)}=(\\pi^{(i)}, p^{(i)}, q^{(i)})$。EM算法的第$i+1$次迭代如下：\n",
    "> \n",
    "> &emsp;&emsp;E步：计算在模型参数$\\pi^{(i)}, p^{(i)}, q^{(i)}$下观测数据$y_j$来自掷硬币B的概率\n",
    "> $$ \\mu_j^{(i+1)} = \\frac{\\pi^{(i)} (p^{(i)})^{y_j} (1-p^{(i)})^{1-y_j}}{\\pi^{(i)} (p^{(i)})^{y_j} (1-p^{(i)})^{1-y_j} + (1-\\pi^{(i)}) (q^{(i)})^{y_j} (1-q^{(i)})^{1-y_j}} $$\n",
    "> &emsp;&emsp;M步：计算模型参数的新估计值\n",
    "> $$ \\pi^{(i+1)} = \\frac{1}{n} \\sum_{j=1}^N \\mu_j^{(i+1)} \\\\\n",
    "p^{(i+1)} = \\frac{ \\displaystyle \\sum_{j=1}^n \\mu_j^{(i+1)} y_j }{ \\displaystyle \\sum_{j=1}^n \\mu_j^{(i+1)} } \\\\\n",
    "q^{(i+1)} = \\frac{ \\displaystyle \\sum_{j=1}^n ( 1 - \\mu_j^{(i+1)} ) y_j }{ \\displaystyle \\sum_{j=1}^n ( 1 - \\mu_j^{(i+1)} ) } $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第3步：编写代码并求出模型参数的极大似然估计**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class ThreeCoinEM:\n",
    "    def __init__(self, prob, tol=1e-6, max_iter=1000):\n",
    "        \"\"\"\n",
    "        初始化模型参数\n",
    "        :param prob: 模型参数的初值\n",
    "        :param tol: 收敛阈值\n",
    "        :param max_iter: 最大迭代次数\n",
    "        \"\"\"\n",
    "        self.prob_A, self.prob_B, self.prob_C = prob\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def calc_mu(self, j):\n",
    "        \"\"\"\n",
    "        （E步）计算mu\n",
    "        :param j: 观测数据y的第j个\n",
    "        :return: 在模型参数下观测数据yj来自掷硬币B的概率\n",
    "        \"\"\"\n",
    "        # 掷硬币A观测结果为正面\n",
    "        pro_1 = self.prob_A * \\\n",
    "            math.pow(self.prob_B, data[j]) * \\\n",
    "            math.pow((1 - self.prob_B), 1 - data[j])\n",
    "        # 掷硬币A观测结果为反面\n",
    "        pro_2 = (1 - self.prob_A) * math.pow(self.prob_C,\n",
    "                                             data[j]) * math.pow((1 - self.prob_C), 1 - data[j])\n",
    "        return pro_1 / (pro_1 + pro_2)\n",
    "\n",
    "    def fit(self, data):\n",
    "        count = len(data)\n",
    "        print(\"模型参数的初值：\")\n",
    "        print(\"prob_A={}, prob_B={}, prob_C={}\".format(\n",
    "            self.prob_A, self.prob_B, self.prob_C))\n",
    "        print(\"EM算法训练过程：\")\n",
    "        for i in range(self.max_iter):\n",
    "            # （E步）得到在模型参数下观测数据yj来自掷硬币B的概率\n",
    "            _mu = [self.calc_mu(j) for j in range(count)]\n",
    "            # （M步）计算模型参数的新估计值\n",
    "            prob_A = 1 / count * sum(_mu)\n",
    "            prob_B = sum([_mu[k] * data[k] for k in range(count)]) \\\n",
    "                / sum([_mu[k] for k in range(count)])\n",
    "            prob_C = sum([(1 - _mu[k]) * data[k] for k in range(count)]) \\\n",
    "                / sum([(1 - _mu[k]) for k in range(count)])\n",
    "            print('第{}次：prob_A={:.4f}, prob_B={:.4f}, prob_C={:.4f}'.format(\n",
    "                i + 1, prob_A, prob_B, prob_C))\n",
    "            # 计算误差值\n",
    "            error = abs(self.prob_A - prob_A) + \\\n",
    "                abs(self.prob_B - prob_B) + abs(self.prob_C - prob_C)\n",
    "            self.prob_A = prob_A\n",
    "            self.prob_B = prob_B\n",
    "            self.prob_C = prob_C\n",
    "            # 判断是否收敛\n",
    "            if error < self.tol:\n",
    "                print(\"模型参数的极大似然估计：\")\n",
    "                print(\"prob_A={:.4f}, prob_B={:.4f}, prob_C={:.4f}\".format(self.prob_A, self.prob_B,\n",
    "                                                                           self.prob_C))\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型参数的初值：\n",
      "prob_A=0.46, prob_B=0.55, prob_C=0.67\n",
      "EM算法训练过程：\n",
      "第1次：prob_A=0.4619, prob_B=0.5346, prob_C=0.6561\n",
      "第2次：prob_A=0.4619, prob_B=0.5346, prob_C=0.6561\n",
      "模型参数的极大似然估计：\n",
      "prob_A=0.4619, prob_B=0.5346, prob_C=0.6561\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "data = [1, 1, 0, 1, 0, 0, 1, 0, 1, 1]\n",
    "# 模型参数的初值\n",
    "init_prob = [0.46, 0.55, 0.67]\n",
    "\n",
    "# 三硬币模型的EM模型\n",
    "em = ThreeCoinEM(prob=init_prob, tol=1e-5, max_iter=100)\n",
    "# 模型训练\n",
    "em.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;可见通过两次迭代，模型参数已经收敛，三硬币正面出现的概率分别为0.4619，0.5346，0.6561"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 习题9.2\n",
    "证明引理9.2。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答思路：**\n",
    "1. 写出需要证明的引理9.2；\n",
    "2. 列出$F$函数定义；\n",
    "3. 根据引理9.1，进行公式推导；\n",
    "4. 根据约束条件$\\displaystyle \\sum_z \\tilde{P}_{\\theta}(Z) = 1$，可证明引理9.2。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答步骤：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第1步：需要证明的引理9.2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;根据书中第9.4.1节的引理9.2：\n",
    "\n",
    "> &emsp;&emsp;**引理9.2** 若$\\tilde{P}_{\\theta}(Z)=P(Z | Y, \\theta)$，则\n",
    "> $$ F(\\tilde{P}, \\theta)=\\log P(Y|\\theta)  \\tag{9.36} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第2步：$F$函数定义**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;根据书中第9章的定义9.3的$F$函数定义：\n",
    "\n",
    "> &emsp;&emsp;**定义9.3（$F$函数）** 假设隐变量数据$Z$的概率分布为$\\tilde{P}(Z)$，定义分布$\\tilde{P}$与参数$\\theta$的函数$F(\\tilde{P}, \\theta)$如下：\n",
    "> \n",
    "> $$ F(\\tilde{P}, \\theta) = E_{\\tilde{P}}[\\log P(Y, Z|\\theta)] + H(\\tilde{P}) \\tag{9.33} $$\n",
    "> \n",
    "> 称为$F$函数。式中$H(\\tilde{P}) = - E_{\\tilde{P}} \\log \\tilde{P}(Z)$是分布$\\tilde{P}(Z)$的熵。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第3步：引理9.1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;根据书中第9章的引理9.1：\n",
    "\n",
    "> &emsp;&emsp;**引理9.1** 对于固定的$\\theta$，存在唯一的分布$\\tilde{P}_{\\theta}$极大化$F(\\tilde{P}, \\theta)$，这时$\\tilde{P}_{\\theta}$由下式给出：\n",
    "> $$ \\tilde{P}_{\\theta}(Z) = P(Z | Y, \\theta) \\tag{9.34} $$\n",
    "> 并且$\\tilde{P}_{\\theta}$随$\\theta$连续变化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{aligned}\n",
    "\\therefore F(\\tilde{P}, \\theta) \n",
    "&= E_{\\tilde{P}}[\\log P(Y, Z|\\theta)] + H(\\tilde{P}) \\\\\n",
    "&= E_{\\tilde{P}}[\\log P(Y,Z|\\theta)] -E_{\\tilde{P}} \\log \\tilde{P}(Z) \\quad （F函数定义：H(\\tilde{P}) = - E_{\\tilde{P}} \\log \\tilde{P}(Z)）\\\\\n",
    "&= \\sum_Z \\log P(Y,Z|\\theta) \\tilde{P}_{\\theta}(Z) - \\sum_Z \\log \\tilde{P}(Z) \\cdot \\tilde{P}(Z)\n",
    "\\end{aligned}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据引理9.1：$\\tilde{P}_{\\theta}(Z) = P(Z | Y, \\theta)$\n",
    "\n",
    "$\\begin{aligned}\n",
    "F(\\tilde{P}, \\theta)\n",
    "&= \\sum_Z \\log P(Y,Z|\\theta) \\tilde{P}_{\\theta}(Z) - \\sum_Z \\log \\tilde{P}(Z) \\cdot \\tilde{P}(Z) \\\\\n",
    "&= \\sum_Z \\log P(Y,Z|\\theta) P(Z|Y,\\theta) -  \\sum_Z \\log P(Z|Y,\\theta) \\cdot P(Z|Y,\\theta) \\\\\n",
    "&= \\sum_Z P(Z|Y,\\theta) \\left[ \\log P(Y,Z|\\theta) - \\log P(Z|Y,\\theta) \\right] \\\\\n",
    "&= \\sum_Z P(Z|Y,\\theta) \\log \\frac{P(Y,Z|\\theta)}{P(Z|Y,\\theta)} \\\\\n",
    "&= \\sum_Z P(Z|Y,\\theta) \\log P(Y|\\theta) \\\\\n",
    "&= \\log P(Y|\\theta) \\sum_Z P(Z|Y,\\theta) \n",
    "\\end{aligned}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第4步：根据引理9.1，得证**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据引理9.1，可知：$\\displaystyle \\sum_Z P(Z|Y, \\theta) = \\sum_Z \\tilde{P}_{\\theta}(Z) = 1$  \n",
    "\n",
    "$\\therefore F(\\tilde{P}, \\theta) = \\log P(Y|\\theta)$，引理9.2得证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 习题9.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "已知观测数据 -67，-48，6，8，14，16，23，24，28，29，41，49，56，60，75，试估计两个分量的高斯混合模型的5个参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答思路：**\n",
    "\n",
    "&emsp;&emsp;两个分量的高斯混合模型一共有6个参数$\\mu_1, \\mu_2, \\sigma_1, \\sigma_2, \\alpha_1, \\alpha_2$，其中$\\alpha_2$可由$\\alpha_2 = 1- \\alpha_1$得到，故仅估计5个参数即可。\n",
    "1. 写出高斯混合模型；\n",
    "2. 写出高斯混合模型参数估计的EM算法；\n",
    "3. 采用sklearn的GaussianMixture计算6个参数；\n",
    "4. 采用自编程实现高斯混合模型的EM算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答步骤：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第1步：高斯混合模型**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;根据书中第9章的定义9.2的高斯混合模型：\n",
    "\n",
    "> &emsp;&emsp;**定义9.2（高斯混合模型）** 高斯混合模型是指具有如下形式的概率分布模型：\n",
    "> $$ P(y | \\theta) = \\sum_{k=1}^K \\alpha_k \\phi(y|\\theta_k) $$\n",
    "> 其中，$\\alpha_k$是系数，$\\alpha_k \\geqslant 0$，$\\displaystyle \\sum_{k=1}^K \\alpha_k = 1$；$\\phi(y|\\theta)$是高斯分布密度，$\\theta_k=(u_k, \\sigma_k^2)$，\n",
    "> $$ \\phi(y|\\theta_k) = \\frac{1}{\\sqrt{2 \\pi} \\sigma_k} \\exp \\left( -\\frac{(y - \\mu_k)^2}{ 2 \\sigma_k^2} \\right) $$\n",
    "> 称为第$k$个分模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上述描述中可知，如果是2个高斯混合分模型，一共需要估计的参数有6个$\\mu_1, \\mu_2, \\sigma_1, \\sigma_2, \\alpha_1, \\alpha_2$，其中$\\alpha_1 + \\alpha_2 = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第2步：高斯混合模型参数估计的EM算法**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;根据书中第9章的算法9.2：\n",
    "\n",
    "> **算法9.2（高斯混合模型参数估计的EM算法）**  \n",
    "> 输入：观测数据$y_1, y_2, \\cdots, y_N$，高斯混合模型；  \n",
    "输出：高斯混合模型参数。  \n",
    "（1）取参数的初始值开始迭代；  \n",
    "（2）E步：依据当前模型参数，计算分模型$k$对观测数据$y_i$的响应度\n",
    "> $$ \\hat{\\gamma}_{jk} = \\frac{\\alpha_k \\phi(y_j | \\theta_k)}{\\displaystyle \\sum_{k=1}^K \\alpha_k \\phi(y_j | \\theta_k)}, \\quad j=1,2,\\cdots,N; \\quad k=1,2,\\cdots,K $$  \n",
    ">（3）M步：计算新一轮迭代的模型参数\n",
    "> $$ \\hat{u}_k = \\frac{\\displaystyle \\sum_{j=1}^N \\hat{\\gamma}_{jk} y_j }{\\displaystyle \\sum_{j=1}^N \\hat{\\gamma}_{jk}}, \\quad k=1,2,\\cdots,K \\\\\n",
    "\\hat{\\sigma}_k^2 = \\frac{\\displaystyle \\sum_{j=1}^N \\hat{\\gamma}_{jk} (y_j - u_k)^2 }{\\displaystyle \\sum_{j=1}^N \\hat{\\gamma}_{jk} }, \\quad k=1,2,\\cdots,K \\\\\n",
    "\\hat{\\alpha}_k = \\frac{\\displaystyle \\sum_{j=1}^N \\hat{\\gamma}_{jk}}{N}, \\quad k=1,2,\\cdots,K $$  \n",
    ">（4）重复第（2）步和第（3）步，直到收敛。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第3步：采用sklearn的GaussianMixture计算6个参数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类结果：labels = [0 0 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "两个分量高斯混合模型的6个参数如下：\n",
      "means = [[-57.51107027  32.98489643]]\n",
      "covariances = [[ 90.24987882 429.45764867]]\n",
      "weights =  [[0.13317238 0.86682762]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 初始化观测数据\n",
    "data = np.array([-67, -48, 6, 8, 14, 16, 23, 24, 28,\n",
    "                29, 41, 49, 56, 60, 75]).reshape(-1, 1)\n",
    "\n",
    "# 设置n_components=2，表示两个分量高斯混合模型\n",
    "gmm_model = GaussianMixture(n_components=2)\n",
    "# 对模型进行参数估计\n",
    "gmm_model.fit(data)\n",
    "# 对数据进行聚类\n",
    "labels = gmm_model.predict(data)\n",
    "\n",
    "# 得到分类结果\n",
    "print(\"分类结果：labels = {}\\n\".format(labels))\n",
    "print(\"两个分量高斯混合模型的6个参数如下：\")\n",
    "# 得到参数u1,u2\n",
    "print(\"means =\", gmm_model.means_.reshape(1, -1))\n",
    "# 得到参数sigma1, sigma1\n",
    "print(\"covariances =\", gmm_model.covariances_.reshape(1, -1))\n",
    "# 得到参数a1, a2\n",
    "print(\"weights = \", gmm_model.weights_.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制观测数据的聚类情况\n",
    "for i in range(0, len(labels)):\n",
    "    if labels[i] == 0:\n",
    "        plt.scatter(i, data.take(i), s=15, c='red')\n",
    "    elif labels[i] == 1:\n",
    "        plt.scatter(i, data.take(i), s=15, c='blue')\n",
    "plt.title('Gaussian Mixture Model')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第4步：自编程实现高斯混合模型的EM算法**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "\n",
    "class MyGMM:\n",
    "    def __init__(self, alphas_init, means_init, covariances_init, tol=1e-6, n_components=2, max_iter=50):\n",
    "        # (1)设置参数的初始值\n",
    "        # 分模型权重\n",
    "        self.alpha_ = np.array(\n",
    "            alphas_init, dtype=\"float16\").reshape(n_components, 1)\n",
    "        # 分模型均值\n",
    "        self.mean_ = np.array(\n",
    "            means_init, dtype=\"float16\").reshape(n_components, 1)\n",
    "        # 分模型标准差（方差的平方）\n",
    "        self.covariances_ = np.array(\n",
    "            covariances_init, dtype=\"float16\").reshape(n_components, 1)\n",
    "        # 迭代停止的阈值\n",
    "        self.tol = tol\n",
    "        # 高斯混合模型分量个数\n",
    "        self.K = n_components\n",
    "        # 最大迭代次数\n",
    "        self.max_iter = max_iter\n",
    "        # 观测数据\n",
    "        self._y = None\n",
    "        # 实际迭代次数\n",
    "        self.n_iter_ = 0\n",
    "\n",
    "    def gaussian(self, mean, convariances):\n",
    "        \"\"\"计算高斯分布概率密度\"\"\"\n",
    "        return 1 / np.sqrt(2 * np.pi * convariances) * np.exp(\n",
    "            -(self._y - mean) ** 2 / (2 * convariances))\n",
    "\n",
    "    def update_r(self, mean, convariances, alpha):\n",
    "        \"\"\"更新r_jk 分模型k对观测数据yi的响应度\"\"\"\n",
    "        r_jk = alpha * self.gaussian(mean, convariances)\n",
    "        return r_jk / r_jk.sum(axis=0)\n",
    "\n",
    "    def update_params(self, r):\n",
    "        \"\"\"更新u al si 每个分模型k的均值、权重、方差\"\"\"\n",
    "        u = self.mean_[-1]\n",
    "        _mean = ((r * self._y).sum(axis=1) / r.sum(axis=1)).reshape(self.K, 1)\n",
    "        _covariances = ((r * (self._y - u) ** 2).sum(axis=1) /\n",
    "                        r.sum(axis=1)).reshape(self.K, 1)\n",
    "        _alpha = (r.sum(axis=1) / self._y.size).reshape(self.K, 1)\n",
    "        return _mean, _covariances, _alpha\n",
    "\n",
    "    def judge_stop(self, mean, covariances, alpha):\n",
    "        \"\"\"中止条件判断\"\"\"\n",
    "        a = np.linalg.norm(self.mean_ - mean)\n",
    "        b = np.linalg.norm(self.covariances_ - covariances)\n",
    "        c = np.linalg.norm(self.alpha_ - alpha)\n",
    "        return True if np.sqrt(a ** 2 + b ** 2 + c ** 2) < self.tol else False\n",
    "\n",
    "    def fit(self, y):\n",
    "        self._y = np.copy(np.array(y))\n",
    "        \"\"\"迭代训练获得预估参数\"\"\"\n",
    "        # (2)E步：计算分模型k对观测数据yi的响应度\n",
    "        r = self.update_r(self.mean_, self.covariances_, self.alpha_)\n",
    "        # 更新r_jk 分模型k对观测数据yi的响应度\n",
    "        _mean, _covariances, _alpha = self.update_params(r)\n",
    "        # 更新u al si 每个分模型k的均值、权重、方差\n",
    "        for i in range(self.max_iter):\n",
    "            if not self.judge_stop(_mean, _covariances, _alpha):\n",
    "                # (4)未达到阈值条件，重复迭代\n",
    "                r = self.update_r(_mean, _covariances, _alpha)\n",
    "                # (3)M步：计算新一轮迭代的模型参数\n",
    "                _mean, _covariances, _alpha = self.update_params(r)\n",
    "            else:\n",
    "                # 达到阈值条件，停止迭代\n",
    "                self.n_iter_ = i\n",
    "                break\n",
    "\n",
    "            self.mean_ = _mean\n",
    "            self.covariances_ = _covariances\n",
    "            self.alpha_ = _alpha\n",
    "\n",
    "    def score(self):\n",
    "        \"\"\"计算该局部最优解的score，即似然函数值\"\"\"\n",
    "        return (self.alpha_ * self.gaussian(self.mean_, self.covariances_)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha : [[0.56950675 0.43049325]]\n",
      "mean : [[27.41762854 12.35515017]]\n",
      "std : [[ 268.17311145 2772.33989897]]\n"
     ]
    }
   ],
   "source": [
    "# 观测数据\n",
    "y = np.array([-67, -48, 6, 8, 14, 16, 23, 24, 28,\n",
    "             29, 41, 49, 56, 60, 75]).reshape(1, 15)\n",
    "# 预估均值和方差，以其邻域划分寻优范围\n",
    "y_mean = y.mean() // 1\n",
    "y_std = (y.std() ** 2) // 1\n",
    "\n",
    "# 网格搜索，对不同的初值进行参数估计\n",
    "alpha = [[i, 1 - i] for i in np.linspace(0.1, 0.9, 9)]\n",
    "mean = [[y_mean + i, y_mean + j]\n",
    "        for i in range(-10, 10, 5) for j in range(-10, 10, 5)]\n",
    "covariances = [[y_std + i, y_std + j]\n",
    "               for i in range(-1000, 1000, 500) for j in range(-1000, 1000, 500)]\n",
    "results = []\n",
    "for i in itertools.product(alpha, mean, covariances):\n",
    "    init_alpha = i[0]\n",
    "    init_mean = i[1]\n",
    "    init_covariances = i[2]\n",
    "    clf = MyGMM(alphas_init=init_alpha, means_init=init_mean, covariances_init=init_covariances,\n",
    "                n_components=2, tol=1e-6)\n",
    "    clf.fit(y)\n",
    "    # 得到不同初值收敛的局部最优解\n",
    "    results.append([clf.alpha_, clf.mean_, clf.covariances_, clf.score()])\n",
    "# 根据score，从所有局部最优解找到相对最优解\n",
    "best_value = max(results, key=lambda x: x[3])\n",
    "\n",
    "print(\"alpha : {}\".format(best_value[0].T))\n",
    "print(\"mean : {}\".format(best_value[1].T))\n",
    "print(\"std : {}\".format(best_value[2].T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 习题9.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;EM算法可以用到朴素贝叶斯法的非监督学习，试写出其算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答思路：**  \n",
    "参考： http://www.cs.columbia.edu/~mcollins/em.pdf\n",
    "\n",
    "1. 列出EM算法；\n",
    "2. 列出朴素贝叶斯算法；\n",
    "3. 推导朴素贝叶斯的EM算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答步骤：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第1步：EM算法**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;根据书中第9章的算法9.1的EM算法：\n",
    "\n",
    "> **算法9.1（EM算法）**  \n",
    "> 输入：观测变量数据$Y$，隐变量数据$Z$，联合分布$P(Y,Z|\\theta)$，条件分布$P(Z|Y,\\theta)$；  \n",
    "输出：模型参数$\\theta$。  \n",
    "（1）选择参数的初值$\\theta^{(0)}$，开始迭代；  \n",
    "（2）E步：记$\\theta^{(i)}$为第$i$次迭代参数$\\theta$的估计值，在第$i+1$次迭代的E步，计算\n",
    "> $$ \\begin{aligned}\n",
    "Q(\\theta,\\theta^{(i)}) &= E_Z[\\log P(Y,Z | \\theta)| Y,\\theta^{(i)}] \\\\\n",
    "&= \\sum_z \\log P(Y,Z | \\theta) P(Z|Y,\\theta^{(i)})\n",
    "\\end{aligned} $$\n",
    "> 这里，$P(Z|Y, \\theta)$是在给定观测数据$Y$和当前的参数估计$\\theta^{(i)}$下隐变量数据$Z$的条件概率分布；  \n",
    "（3）M步：求使$Q(\\theta, \\theta^{(i)})$极大化的$\\theta$，确定第$i+1$次迭代的参数的估计值$\\theta^{(i+1)}$\n",
    "> $$ \\theta^{(i+1)} = \\arg \\max \\limits_{\\theta} Q(\\theta, \\theta^{(i)}) $$\n",
    ">（4）重复第（2）步和第（3）步，直至收敛。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第2步：朴素贝叶斯算法**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;根据书中第4章的算法4.1的朴素贝叶斯算法：\n",
    "\n",
    "> **算法4.1（朴素贝叶斯算法）**  \n",
    "> 输入：训练数据$T={(x_1, y_1), (x_2, y_2), \\cdots, (x_N, y_N)}$，其中$x_i=(x_i^{(1)}, x_i^{(2)}, \\cdots, x_i^{(n)})^T$，$x_i^{(j)}$是第$i$个样本的第$j$个特征，$x_i^{(j)} \\in \\{a_{j1}, a_{j2},\\cdots, a_{j S_j}\\}$，$a_{jl}$是第$j$个特征可能取的第$l$个值，$j=1,2,\\cdots, n$，$l=1,2,\\cdots, S_j$，$y_i \\in \\{ c_1, c_2, \\cdots, c_K\\}$；实例$x$；  \n",
    "输出：实例$x$的分类。  \n",
    "（1）计算先验概率及条件概率\n",
    "> $$ P(Y=c_k) = \\frac{\\displaystyle \\sum_{i=1}^N I(y_i=c_k)}{N}, \\quad k=1,2,\\cdots, K \\\\\n",
    "P(X^{(j)}=a_{jl}|Y=c_k)= \\frac{\\displaystyle \\sum_{i=1}^N I(x_i^{(j)} = a_{jl}, y_i=c_k) }{\\displaystyle \\sum_{i=1}^N I(y_i=c_k)} \\\\\n",
    "j=1,2,\\cdots,n; \\quad l=1,2,\\cdots, S_j; \\quad k=1,2,\\cdots, K $$  \n",
    ">（2）对于给定的实例$x=(x^{(1)}, x^{(2)}, \\cdots, x^{(n)})^T$，计算\n",
    "> $$ P(Y=c_k) \\prod_{j=1}^n P(X^{(j)}=x^{(j)} | Y=c_k), \\quad k=1,2,\\cdots,K $$  \n",
    ">（3）确定实例$x$的类\n",
    "> $$ y = \\arg \\max \\limits_{c_k} P(Y=c_k) \\prod_{j=1}^n P(X^{(j)}=x^{(j)} | Y=c_k) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第3步：推导朴素贝叶斯的EM算法**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推导思路：\n",
    "1. 假设隐变量数据是$y \\in \\mathcal{Y} = \\{c_1, c_2, \\cdots, c_K\\}$\n",
    "2. 设置初值，$P^{(0)}(Y=y) \\geqslant 0$和$P_j^{(0)}(X=x|Y=y) \\geqslant 0$，其中$j = 1,2,\\cdots, n$，满足\n",
    "$$\n",
    "\\sum_{y \\in \\mathcal{Y}} P^{(0)}(Y=y) = 1 \\\\\n",
    "\\sum_{x \\in \\{-1, +1\\}} P_j^{(0)}(X=x|Y=y)=1\n",
    "$$\n",
    "3. 根据概率公式，可知概率\n",
    "$$\n",
    "\\delta(y|i) = P(Y=y | X=x_i, \\theta^{(t)}) = \\frac\n",
    "{\\displaystyle P^{(t)}(Y=y) \\prod_{j=1}^n P_j^{(t)}(X=x_i^{(j)} | Y=y) }\n",
    "{\\displaystyle \\sum_{y \\in \\mathcal{Y}} P^{(t)}(Y=y) \\prod_{j=1}^n P_j^{(t)}(X=x_i^{(j)} | Y=y)}\n",
    "$$\n",
    "其中$\\theta$表示朴素贝叶斯模型中所有的参数向量\n",
    "4. 迭代更新参数\n",
    "$$\n",
    "P^{(t+1)}(Y=y) = \\frac{1}{N} \\sum_{i=1}^N \\delta(y | i) \\\\\n",
    "P_j^{(t+1)}(X=x_i^{(j)} | y) = \\frac\n",
    "{\\displaystyle \\sum_{i=1}^N P(X=x_i^{(j)})\\delta(y|i) }\n",
    "{\\displaystyle \\sum_{i=1}^N \\delta(y|i)}\n",
    "$$\n",
    "5. 计算似然函数，得到使得似然函数最大的$\\theta$，重复第3步和第4步，直至收敛\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\theta^* &= \\arg \\max \\limits_{\\theta \\in \\Omega} L(\\theta) \\\\\n",
    "&= \\arg \\max \\limits_{\\theta \\in \\Omega} \\sum_{i=1}^N \\sum_{y \\in \\mathcal{Y}} \\delta(y|i) \\log \\left(P(Y=y) \\prod_{j=1}^n P_j (X=x_i^{(j)} | Y=y)\\right)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以，朴素贝叶斯的EM算法如下：\n",
    "\n",
    "输入：隐变量数据是$y \\in \\mathcal{Y} = \\{c_1, c_2, \\cdots, c_K\\}$，$x \\in \\mathcal{X} = (x_1, x_2, \\cdots, x_N)$，输入空间$\\mathcal{X} \\subset R^n$为$n$维向量的集合，$x=(x^{(1)}, x^{(2)}, \\cdots, x^{(n)})^T$，$x^{(i)}$取值范围是$\\{-1, +1\\}$；  \n",
    "输出：参数$P^{(t+1)}(Y=y)$，$P_j^{(t+1)}(X=x_i^{(j)} | y)$；  \n",
    "（1）选择参数的初值$P^{(0)}(Y=y) \\geqslant 0$和$P_j^{(0)}(X=x|Y=y) \\geqslant 0$，开始迭代；  \n",
    "（2）E步：记$\\theta^{(t)}$为第$t$次迭代参数$\\theta$的估计值，在第$t+1$次迭代的E步，计算 $$\n",
    "\\delta(y|i) = P(Y=y | X=x_i, \\theta^{(t)}) = \\frac\n",
    "{\\displaystyle P^{(t)}(Y=y) \\prod_{j=1}^n P_j^{(t)}(X=x_i^{(j)} | Y=y) }\n",
    "{\\displaystyle \\sum_{y \\in \\mathcal{Y}} P^{(t)}(Y=y) \\prod_{j=1}^n P_j^{(t)}(X=x_i^{(j)} | Y=y)}\n",
    "$$ \n",
    "（3）M步：求使$Q(\\theta, \\theta^{(t)})$极大化的$\\theta$，确定第$t+1$次迭代的参数的估计值\n",
    "$$\n",
    "P^{(t+1)}(Y=y) = \\frac{1}{N} \\sum_{i=1}^N \\delta(y | i) \\\\\n",
    "P_j^{(t+1)}(X=x_i^{(j)} | y) = \\frac\n",
    "{\\displaystyle \\sum_{i=1}^N P(X=x_i^{(j)})\\delta(y|i) }\n",
    "{\\displaystyle \\sum_{i=1}^N \\delta(y|i)}\n",
    "$$\n",
    "（4）重复第（2）步和第（3）步，直至收敛。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
